# Deep Learning for Entity Matching: A Design Space Exploration

# 1.介绍

实体匹配（EM）是指找到指向现实世界中某个实体的数据实例。这个问题在数据清理和整合中很重要，但目前还没有让人满意的解决方案。本文研究深度学习（DL）在实体匹配上应用的情况。

EM中最常见的类型是匹配结构化的数据实例，例如名字、年龄这些属性值是简短和原子化的元组。

另一种是文本化的数据实例，例如利用公司的主页和维基百科中公司的描述进行匹配，传统EM方法对这种长文本的实例可能效果并不好，而DL可能对这种问题有比较好的效果。

还有一种是那些结构化但不准确（脏）的数据。例如在分离属性时将“皮革红“分为了颜色，但只有”红“是颜色，”皮革“是材料，这就导致了材料这一栏会出现空属性。传统的EM方法对这种情况效果不好。而DL是将整段文本作为实例来处理，无视属性的边界，因此可能对这种情况效果比较好。

# 2.准备工作

## 2.1实体匹配

### 问题设定

有D和D'两个mention集，有相同的属性结构。EM的目的是找出二者之间指向同一个现实实体的pair。匹配分为两步：先在DXD'的交叉集中进行过滤，得到只包含可能会匹配的pair集合，再用一个匹配器来确认正确的匹配对。

对于匹配这一步，设定一个集合T（e<sub>1</sub>，e<sub>2</sub>，l），其中e<sub>1</sub>和e<sub>2</sub>分别是D和D'中的mention，l表示匹配或不匹配。我们将T作为训练集来训练匹配器M。

### EM问题的类型

1. 结构化EM：D和D'有着相同格式和对齐的属性，且文本属性有长度限制。
2. 文本化EM：所有属性都是原始文本。
3. 脏EM：D和D'中的mention是结构相同的记录，但属性值可能与属性不对应。

## 2.2深度学习

递归神经网络：隐藏层保留一个状态向量，每次用该向量参与计算输出，并用计算结果更新该向量，即该向量包含了之前所有输入的信息。

传统的递归神经网络认为输入序列的部分重要程度相同，但对于比较长或者有噪声的输入序列来说不同部分重要性不同。一种attention机制用来解决上述问题，该模型除了基本输入外还输入n个参数。

## 2.3NLP匹配任务中的DL方案

- 实体链接

  > 实体链接是指将输入文档中的实体mentions连接到知识库中的实体，和EM的区别在于知识库中包含附加的信息例如实体之间的关系。

- 共指消解

  > 目标在于识别并分类输入文档中指向同一现实实体的短语。

- 文本蕴含和语义相似度

  > 文本蕴含决定了一个句子的涵义是否蕴含了另一个句子的涵义，例如“猫在捉老鼠”蕴含“猫在移动”。前者为前提，后者为假设，前者可以推导出后者。

- 回答问题

  > 任务是用现存的文章或知识库回答自然语言问题。

- DL方案的分类

  > 目前讨论到的所有模型都进行序列化的输入，将输入序列进行向量表示，再将两个序列进行比较。所有模型归于3个维度：
  >
  > - 语言表示（词向量）
  > - 概括输入（RNN、attention机制）
  > - 序列比较（神经网络）

# 3.DL方案

## 3.1结构模板与设计空间

### ①属性向量模块

输入两个mention的属性序列对，某个属性中包含m个元素，则将其转化为d×m维向量，依次输出每个属性下的向量对。

### ②属性相似度表示模块

对每个属性及对应的属性对，进行以下两步操作：

1. 属性概括：对每个属性下的向量对，将d×m向量转化为h维向量。
2. 属性比较：对转化后的两个向量进行比较。

输出是N维向量，每一维表示一个属性的比较结果。

### ③分类模块

将相似度向量作为输入，决定二者是否指向同一实体。

---

上述每个模块的方案：

![image-20201129105123010](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20201129105123010.png)

## 3.2属性向量方案

属性向量模块可用两个维度来描述：

- 向量的粒度
- 是否使用预训练向量或特定领域向量

### 词语级别和字符级别

词语级别的向量编码：用大型语料库训练出一张表，通过查表将每个词转化成d维向量，对于不在表中的词（OOV），同一用UNK替代。

字符级别的向量编码：将每个词的字母表示作为输入，然后用神经网络生成该词的d维向量。转化工具为训练好的模型，可以对任何由已知字符构成的词语进行处理。核心思想是词语是由有意义的字符序列组成的，例如kindness由kind和ness组成。

字符级对低频词有更好的效果，对OOV（拼写错误等）更加健壮。

### 预训练和学习向量

预训练优势：

- 很小的端到端训练延迟
- 通过大型语料库训练，因此对语言差异更加健壮

不适合语义高度专业化的领域。

## 3.3属性概括方案（H）

### 聚合函数

求d×m向量每一维的平均或加权平均，这样得到的向量也是d维的。这种方案很高效，但不能处理词语之间复杂的联系，非常依赖于词向量的质量。

### 序列感知型概括

此方案旨在学习输入序列之间的复杂关系，d×m向量转化为h维向量。此方案可以通过RNN实现，将序列输入到RNN中，得到隐藏层状态序列，再将最后一个隐藏层状态或者所有隐藏层状态的平均值作为相似度输出。该方法的局限性：

- 序列很长时不学习其意义表示
- 不会将输入对序列结合起来分析来识别共同的上下文，这可能会导致严重的性能下降。

### 序列对齐

将两个输入序列中的一个作为上下文来概括另一个，可以建立在注意力机制上。先在两个输入序列之间的词语进行软对齐，然后进行词与词的比较。缺点：只使用给定的上下文，忽略原始输入序列的上下文。（？）

## 3.4属性比较方案（D）

1. 固定距离函数

   > 用预先设定好的距离标准，如余弦距离或欧氏距离，输出是标量，衡量个mention的相似度。这此方案的训练时间很少但使属性值的相似度有很高的优先级。

2. 可学习距离函数

   > 这里D会输出一个l维的向量，作为分类模块的输入，可以采用级联、绝对差值、绝对乘积或这些的混合来执行D。

# 4.EM中代表性的DL方法

本节介绍4种DL方法:SIF, RNN, Attention, and Hybrid。都使用fastText（一种预训练的字符级的向量）来实现属性向量。结构：两层全连接层，一层softmax层。

## 4.1SIF：聚合函数模型

用加权平均求属性概括，通过绝对差值进行比较，并形成分类模块的输入。输入序列中每个词w的权重由以下公式给出：
$$
f(w)=a/(a+p(w))
$$
其中a是一个超参数，p(w)是w在输入语料库中的归一化频率。

该方法简单但有效，效果依赖于属性向量的表达能力和使用的分类器。权重方案采用了Smooth Inverse Frequency（SIF）。

## 4.2RNN：顺序感知模型

用双向RNN求属性概括，通过绝对差值进行比较，并形成分类模块的输入。模型包含两个RNN：

- 正向RNN：按输入顺序处理词向量并生成隐含层状态。
- 反向RNN：按输入的反向顺序生成隐含层状态。

最终的属性概括由这两个RNN的最后输入结合。

## 4.3Attention：序列校准模型

用可分解attention来实现属性概括，用向量结合来进行比较。该模型将两个输入序列结合起来联系，在两个序列之间进行软对齐和成对符号比较。输入序列u1，u2，属性概括步骤：

1. 软对齐

   > 对u1中的每个元素u1[k]，用u2中的所有元素计算其软对齐编码b1[k]。
   >
   > 首先通过一个两层的HighwayNet得到u1[k]和u2[m]的隐含表示，再对其进行点积和对数转换，得到一个权值。对u1和u2中所有每一对进行权值计算，得到一个软对齐矩阵W，其每一行表示u1中的一个元素，每一列表示u2中的一个元素。
   >
   > 再用W中第k行的所有权值对u2的每个元素求加权平均，得到b1[k]。

2. 比较

   > 用一个两层的包含非线性EeLU的HighwayNet，比较u1中的每个元素u1[k]和它的软对齐编码b1[k]，比较结果记为x1[k]（向量表示）。

3. 聚合

   > 将u1中的每个元素的比较结果xi求和，除以√|u1|进行归一化。

上述步骤重复对u2执行一次，以u1为上下文。

## 4.4Hybrid：含有Attention的序列感知

用包含分解attention的双向RNN进行属性概括，用绝对差值进行增强型的向量结合，来实现属性比较并生成分类模块的输入。步骤：

1. 软对齐

   > 和attention一样构建一个软对齐矩阵，计算u1中每个元素的软对齐编码，但对于u2，其软对齐编码是通过将u2传到一个Bi-RNN并结合该RNN的所有隐含层状态。将这个RNN基座RNN1。

2. 比较

   > 为了得到b1和u1的比较结果，进行以下操作：
   >
   > 1. 通过将u1传到RNN1并结合所有隐含层状态，得到u1的编码u1'。
   > 2. 对u1'和b1进行比较，同样使用一个两层的包含非线性EeLU的HighwayNet，比较结果即为x1。

3. 聚合

   > 用一种加权平均方案对x1进行聚合。x1中每个元素的权值由以下步骤得到：
   >
   > 1. 用一个Bi-RNN（RNN2）处理u2并将最终的隐含层状态作为u2的编码g2.
   > 2. 通过将x1[k]和g2结合并输入一个两层ReLU HighwayNet和一个soft-max层，得到x1中每个元素的权重。该步骤将u2作为上下文来衡量x1中每个元素的重要性。
   > 3. 通过上述权重计算x1中所有元素的加权平均。

同样的步骤对u2进行一次。

# 5.实验评价

实验测试4种DL方法与Magellan的效果：

- 结构化：两种方法结果差不多，但DL所需的训练时间远超EM。


- 文本化：DL比EM更为出色，准确率高3%-22%。


- 脏实例：DL比EM更为出色，准确率高6.2%-32.6%。

影响模型表现的因素：

- 训练量较少时，用软对齐进行概括的模型效果更好
- 训练量较多时，简单模型和复杂模型效果差不多

总体来说4种DL方法中Hybrid效果最好。

# 6.讨论

## 6.1DL学了什么

Hybrid能够对包含重要的语义信息的符号赋予更高的权重，如产品序列号、人名地名。DL模型的主要错误原因在于：

- 特定领域的术语含义变化
- 错过高度信息化的符号
- 相似但语义不同的符号

## 6.2挑战和机会

### 挑战

- 尖端先进的DL方法在整齐、结构化的数据处理上相较于简单的学习模型优势不大
- 复杂的DL方法在文本化和脏的数据上表现更好，但需要远超EM方法的训练时间。
- DL方法经常需要大量的训练数据来达到比较好的效果，但大量的训练数据意味着大量的资源消耗。需要研究新的适用于EM的弱监督学习。

### 机会

- DL在数据整合（DI）领域效果很好，例如数据清洗、自动数据提取、数据重构、数值规范化。
- 在构建DL模型时可以从多个方面进行优化
- DL在理解特定领域语义时表现不佳，一种可能的研究是探索一种机制能让DL模型学习特定领域的知识。