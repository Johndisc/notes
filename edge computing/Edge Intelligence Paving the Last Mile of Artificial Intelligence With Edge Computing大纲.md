# Edge Intelligence Paving the Last Mile of Artificial Intelligence With Edge Computing

# 1.介绍

AI中的深度学习快速发展，大数据源正在迅速从大规模的云端数据中心转变到终端设备，从而使边缘AI应用迅速发展。

想把AI扩展到边缘生态并不容易，面临着性能、成本和隐私问题。一种思路是将终端设备的数据传输到云数据中心进行分析，但金钱成本太高，传输时延太高，且可能发生隐私泄露。另一种思路是在本地运行AI程序，但性能太差且能耗效率低。

边缘计算用于解决上述问题，WIFI AP、路由器、网关、基站都能作为边缘节点，相较于云计算有低延迟、能耗效率高、隐私保障、带宽占用低、本地化和场景感知等优点，与AI相结合即是边缘智能（EI）。

# 2.AI基础概念和深度学习

深度学习：利用人工神经网络来学习数据的深层表现，应用于图像分类、人脸识别等，在边缘计算领域非常合适。其模型称为深度神经网络（DNN）。3种主流结构：

- 多层感知机（MLPs）

- 卷积神经网络（CNNs）
- 递归神经网络（RNNs）

训练过程：先给模型中的权重随机赋初值，用损失函数衡量准确度，用优化算法（例如SGD）来更新权值，通过大量样本进行训练直到错误率低于一个门槛，就得到一个深度学习模型。

1. 卷积神经网络
2. 递归神经网络
3. 生成对抗网络
4. 深度强化学习

# 3.边缘智能（EI）

## A.边缘智能的动机和好处

边缘计算旨在协调边缘设备信息，AI对数据进行学习，二者相结合对两边又有利，有以下几个方面。

1. AI对边缘网络产生的数据处理有很大作用
2. 边缘计算可以用丰富的数据和场景促进AI发展
3. 边缘计算对于AI的普及很重要
4. AI能帮助实现边缘计算的普及

## B.边缘计算的范围和等级

边缘-云端协同工作与本地执行相比既能减少端到端延迟也能减少能耗。目前有关EI的主要想法是在云端进行训练，在边缘进行预测，因为训练阶段更耗资源。但这样设计需要将边缘的大量数据传输到云端，会导致高昂通讯成本和数据泄露风险。

因此，一种新的思路是利用终端设备、边缘节点和云数据中心的多级结构来协同处理数据。集体来说，EI被分为6层：

![image-20201124102739078](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20201124102739078.png)

1. 云端智能：完全在云端训练和预测
2. 第1级：云端训练，数据部分传到云端，云端边缘协同预测
3. 第2级：云端训练，数据部分或全部分到边缘节点或附近设备，实现网络边缘预测
4. 第3级：云端训练，完全在本地设备上进行预测
5. 第4级：训练和预测都采用边缘云端协同的方式
6. 第5级：训练和预测都在边缘节点进行
7. 第6级：训练和预测都在终端设备进行

随着等级的上升，数据传输的量和距离在减少，传输时延在减少，隐蔽性上升，带宽消耗减少，但计算延迟和能耗增加。

# 4.边缘智能模型训练

## A.结构

3种分布式DNN训练结构：中心化、去中心化、混合型。

1. 中心化

   > 边缘设备生成并上传数据到云端，云端进行训练。对应的层次有1、2、3。

2. 去中心化

   > 每个边缘节点本地训练模型并保留私人数据，在节点网络中相互交流模型变化和改进，得到全局DNN模型，无需云端参与。对应的层次为5.

3. 混合型

   > 中心化和去中心化相结合，边缘服务器可以既可以与边缘节点相互更新，也可以直接在云端训练，来得到DNN模型。对应的层次为4、5.

## B.主要的性能指标

1. 训练损失
2. 收敛。主要针对去中心化结构，该指标衡量去中心化结构以多快的速度收敛到一个模型。
3. 隐私。在将终端设备的数据传到边缘设备时要保证数据隐秘性。
4. 通讯成本
5. 延迟。主要包括计算时延和通讯时延。
6. 能源效率

## C.技术

1. 联邦学习

   > 主要用于优化隐私问题。将原始数据保留在客户端上（终端设备），通过合并其他设备计算的更新来训练出共享的模型。其主要挑战在于优化和通讯。
   >
   > - 优化的主要挑战是通过把梯度更新分布到移动设备上来优化梯度。在这方面，联邦学习采用SGD，用整个数据集的一个很小的子集来更新梯度。另一种选择性的SGD（SSGD）让客户端用自己的数据集训练，并选择性地将自己模型重要参数的一部分共享到中心化的聚合中。这样做一方面保护了用户隐私，另一方面通过共享模型降低了训练损失。
   > - 通讯的主要问题在于网络的不可靠和不可预测。联邦学习需要每个客户端向服务器发送完整或部分模型，当模型很大网络就会成为瓶颈。一种思路是用两种新的更新模式来减少通讯成本：结构化更新和草图更新。结构化更新中，模型直接在一个用少数变量进行约束的空间中进行更新；草图更新中，模型先把整个更新学习下来，再用量化、随机旋转和二次采样进行压缩，最后发送给服务器。
   >
   > 虽然联邦学习提供了一种新的去中心化的深度学习架构，但它需要一台中央服务器来聚合更新。为了实现完全去中心化的网络，一种方法是基于贝叶斯的分布式算法：每个设备都聚合离自己一跳的邻居的信息来训练自己的模型。另一种是利用区块链实现设备的模型更新。

2. 聚合频率控制

   > 该方法与用于优化DNN训练时的通讯成本。边缘训练的一种想法是先在本地训练分布模型，再集中聚合更新，在这种情况下聚合的频率对通讯成本有很大影响。
   >
   > Gaia系统和近似同步并行（ASP）模型：基本的思想是将数据中心之间的通讯分离成内部的通信，实现每个数据中心不同的交流和一致的模型。最后ASP模型动态消除数据中心之间不重要的通讯，同时聚合频率由一个预设的门槛控制。然而Gaia要求数据中心的容量没有限制，因此不适用于边缘计算。

3. 梯度压缩

   > 降低通讯成本的另一种方法是梯度压缩，主要方式是梯度量化和梯度稀疏化。梯度量化通过量化向量的每个元素到一个比较低的精准度来实现梯度向量的有损压缩。梯度稀疏化通过发送梯度向量的一部分来降低通讯成本。
   >
   
4. DNN分割

   > 通过只传输部分处理过的数据而不是原始数据来保护隐私。DNN分割在终端设备和边缘服务器之间运行，基于的原理是：DNN模型中的两个相邻层可以被分割为两部分，分别部署在不同位置，且不会损失准确度。
   >
   > 问题在于如何选取分割点。一种是利用差异私有机制在第一个卷积层之后划分DNN。Arden为了利用云数据中心的计算力，用随机使数据无效化和添加随机添加噪声的方法处理数据，来实现隐私保护。并使用一种噪声训练方法保证云-边缘网络对处理后的数据的健壮性。
   >
   > DNN分割除了用于保护隐私，也对大量的DNN计算有帮助。边缘计算包含大量设备，因此并行化经常用于管理DNN计算。并行化包含两种：数据并行和模型并行。数据并行导致很高的通讯成本，模型并行导致严重的计算资源的不充分利用。管道并行用于增强模型并行，通过一次将大量小批量任务输入系统来保证计算资源的高效和并行利用。

5. 知识转移学习

   > 与DNN分割技术有很强的联系。为了减少DNN模型训练的能耗，先在一个基础数据集上训练一个基础网络，再把它转移到第二个目标网络上基于目标数据集进行训练。

6. 流言训练

   > 基于随机流言算法，去中心化训练方法，旨在降低训练延迟。随机流言算法的早期工作是流言平均，能够通过节点之间交换信息快速收敛到一个共识。流言分布算法的优点是完全异步和完全去中心化，基于此提出Gossip SGD（GoSGD）。GoSGD管理一群独立的节点，每个节点有一个DNN模型，迭代执行两步：梯度更新和混合更新。即在本地进行梯度更新，再把信息共享给另一个随机选择的节点进行混合更新，直到所有DNN达成共识。
   >
   > 把gossip SGD部署到大规模系统时，会出现通讯不平衡、收敛效果差和繁重的通讯开销。为了解决上述问题提出GossipGraD,能够将通讯开销复杂度从Θ(log(p))降到O(1)，并考虑了扩散使计算机点在每log(p)步后间接交换更新。

## D.现有系统和框架的概述

![image-20201125121610167](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20201125121610167.png)

分布式EI模型训练的关键挑战是数据隐私问题。去中心化结构对用户数据隐私性更加友好。

# 5.边缘智能模型预测

本节介绍边缘的DNN模型预测。

## A.结构

几种以边缘为中心的预测结构：

1. 基于边缘

   > 设备将输入数据传到边缘服务器，在边缘服务器完成预测，结果送回设备。优点在于容易在不同的移动设备上编写程序，缺点在于预测取决于设备和服务器之间的网络带宽。

2. 基于设备

   > 设备从边缘服务器获取模型并在本地完成预测，对本次设备的资源要求较高。

3. 边缘-设备

   > 设备根据实际情况将DNN模型分成多个部分，先自己执行到一定的层数，把中间数据送到边缘服务器，边缘服务器执行剩下层的计算并把预测结果送回设备。这种结构更加灵活和可靠，由于DNN模型的前几层对计算性能要求也比较高，因此这种结构对设备资源也要求比较高。

4. 边缘-云。

   > 设备只收集数据，DNN模型由边缘和云端协同执行，性能非常依赖网络条件。

## B.主要性能指标

1. 延迟
2. 准确率
3. 能耗
4. 隐私
5. 通讯开销
6. 内存占用

## C.使能技术

本节介绍一些改善上述性能指标的使能技术。

1. 模型压缩

   > 模型压缩对延迟、能耗、隐私和内存占用都有优化，压缩技术包括：权值裁剪、数据量化、紧凑结构设计。
   >
   > 权值裁剪是应用最广泛的压缩技术，删除掉模型中多余的权值。步骤是先根据模型中神经元的贡献对其进行排行，然后删除贡献较低的神经元来减少模型大小，但删除神经元会损害模型的准确度，一些研究着手于减少其损失。然而对于终端设备来说权值裁剪并不会带来可观的节能效果，因为DNN中卷积层消耗大部分能源，而全连接层包含大多数权值，因此权值并不是能耗的主要原因。
   >
   > 数据量化不采用32位浮点数格式，而用一种更紧凑的格式来表示数据，节省内存占用，加速计算。
   >
   > 除此之外，将多种压缩技术相结合也能达到比较好的效果。而对于不同的系统和场景，应该对结合的压缩技术进行筛选。

2. 模型分块

   > 主要思想是将模型进行分块，将需要计算资源的部分分给边缘服务器或附近的移动设备执行。主要考虑延迟、能耗、隐私问题。两种分块模式：服务器与设备之间分块，设备与设备之间分块。
   >
   
3. 提前退出模型

   > 该方法利用前几层的输出数据获得分类结果，即只使用了一部分模型，主要优化目标是延迟。
   >
   
4. 边缘缓存

   > 主要思想是缓存预测结果

5. 输入过滤

   > 主要与用于视频分析，主要思想是删除没有目标物体的帧的帧。

6. 模型选择

   > 离线训练一系列大小不同的DNN模型，适应性地选择模型用于在线预测。

7. 支持多租户

   > 在同一个终端或边缘设备上往往要同时运行多个DNN应用，因此需要合理进行资源分配和任务调度。多租户支持就是用于解决上述问题。
   
8. 特定应用的优化

   > 对特定的应用进行优化。例如视频分析，能耗降低时准确度也会降低，反之亦然，因此如何权衡这两者的关系很重要。

## D.现有系统和框架的概述

![image-20201126093548975](C:\Users\DELL\AppData\Roaming\Typora\typora-user-images\image-20201126093548975.png)

# 6.未来研究方向

## A.编程和软件平台

EI服务的挑战：

- 由于终端设备的差异性，EI平台应该有足够的兼容性。
- 不同框架训练的模型应该具有便携性
- 需要一种在各个指标上都表现足够好的框架
- 轻量级虚拟化和计算基数（容器、函数式计算）

## B.资源友好型的边缘AI模型设计

大多数深度学习模型都对资源的要求很高，因此降低模型能耗对边缘AI来说很重要。可以利用自动机器学习和神经结构搜索技术来发明节能的边缘AI模型。

## C.计算感知网络技术

由于EI中的AI应用一般是在分布式的边缘计算环境上运行的，因此网络对节点之间共享数据十分重要。5G在降低延迟上有很大作用；自主网络技术对不同的网络共存很重要，能够让新加入的边缘节点和设备自动配置；计算感知通讯技术能够加速边缘AI模型训练。

## D.各种DNN性能指标的权衡设计

准确度、预测速度、能耗等指标之间需要进行权衡。

## E.智能服务和资源管理

由于不同的边缘设备和节点会运行不同的AI模型，因此需要设计高效的服务搜索协议来让用户定位到满足其需求的EI服务；需要将复杂的AI模型划分成小的子任务并分配到边缘节点和设备上来实现资源的最大化利用；由于边缘服务环境的动态性，还需要设计良好的资源编排和提供策略。

## F.安全和隐私

由于边缘计算的开放式环境，对数据的隐私保护十分重要。需要设计轻量级和分布式的安全机制来保证用户认证、权限控制、模型和数据 的完整性和交互平台的认证。

## G.激励和商业模式

边缘生态系统包括平台提供商、AI软件提供商、边缘设备提供商、网络运营商、数据源和服务消费者。EI服务的高效执行需要不同的服务提供商之间的紧密合作。因此需要设计合适的激励机制和定价策略。